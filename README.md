
# ğŸ“ˆ Stock Market ETL with Apache Airflow

Este proyecto implementa un pipeline de tipo ETL (Extract, Transform, Load) usando **Apache Airflow** para obtener datos histÃ³ricos del precio de acciones (NVDA), transformarlos con **Apache Spark**, y almacenarlos en una base de datos **PostgreSQL**. Los datos procesados luego son visualizados en un dashboard creado con **Metabase**.

## ğŸš€ TecnologÃ­as utilizadas

- ğŸ› ï¸ Python
- â±ï¸ Apache Airflow
- ğŸ˜ PostgreSQL
- ğŸ³ Docker / Docker Compose
- ğŸ§  Apache Spark (contenedor auto-destructivo)
- ğŸª£ MinIO (almacenamiento tipo S3)
- ğŸ“Š Metabase (dashboarding)
- ğŸŒ API de mercado de valores

## ğŸ§© Arquitectura del proyecto

```mermaid
flowchart TD
    API[API - Stock Prices] --> Airflow
    Airflow --> MinIO
    MinIO --> Spark
    Spark --> PostgreSQL
    PostgreSQL --> Metabase
```

## âš™ï¸ Funcionalidades

- AutomatizaciÃ³n de un flujo ETL con DAGs en Airflow
- Contenedor de Spark que se ejecuta y destruye automÃ¡ticamente tras procesar los datos
- Transformaciones con Spark DataFrames
- Almacenamiento temporal con MinIO (tipo S3)
- Almacenamiento final en PostgreSQL
- VisualizaciÃ³n de KPIs como el promedio de precios con Metabase

## ğŸ“ Estructura del repositorio

```
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ stock_etl_dag.py        # DAG principal de Airflow
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ spark/
â”‚       â””â”€â”€ Dockerfile          # Imagen personalizada para Spark
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ transform.py            # Script de Spark para transformaciÃ³n de datos
â”œâ”€â”€ metabase/                   # Archivos de configuraciÃ³n opcional
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt            # Dependencias
â””â”€â”€ README.md                   # Este archivo
```

## ğŸ§ª CÃ³mo ejecutar el proyecto localmente

```bash
# Clonar el repositorio
git clone https://github.com/Pulixe/Stock-Market-ETL_-ApacheAirflow
cd Stock-Market-ETL_-ApacheAirflow

# Levantar servicios
docker-compose up --build

# Accede a Airflow en:
http://localhost:8080

# Usuario: airflow
# ContraseÃ±a: airflow

# Accede a Metabase en:
http://localhost:3000
```

## ğŸ“Š Ejemplo del dashboard

El dashboard de Metabase incluye visualizaciones como:

- Promedio del precio de cierre
- Volumen de transacciones
- GrÃ¡ficos de tendencias por dÃ­a

## ğŸ“Œ Lecciones aprendidas

- OrquestaciÃ³n efectiva de tareas con Airflow
- Uso de MinIO como sistema de archivos intermedio
- ContenerizaciÃ³n de Spark para procesamiento por lotes
- IntegraciÃ³n completa de un stack ETL moderno
- Mejora de mis habilidades en Python orientado a datos

## ğŸ§  Autor

**Francisco Pulice Rojas**  
ğŸŒ [www.pulixe.info](http://www.pulixe.info)   
ğŸ“‚ [Otros repositorios](https://github.com/Pulixe)

---

Este proyecto fue desarrollado como parte del curso de Apache Airflow de Marc Lamberti en Udemy.

